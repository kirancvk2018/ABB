{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1srx3LSZh4C5",
        "outputId": "e011c91f-82e5-4f5a-8229-916bdffed440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers pandas scikit-learn gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "xGbEo7B1iP-v",
        "outputId": "a2780394-da89-4cb7-f41c-cfad6bce82c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-530d5994-6044-4741-a952-918d4fbe0c9b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-530d5994-6044-4741-a952-918d4fbe0c9b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving external_data_rag_demo.csv to external_data_rag_demo.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload external_data_rag_demo.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxpRr2nGlEF_"
      },
      "source": [
        "# Sample Data\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "eK8d0S4wmpxe",
        "outputId": "af78e45f-040c-4ddf-cbfb-508216d9bf08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://63b96aea3c50f28042.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://63b96aea3c50f28042.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "# Global variable to store previous answers\n",
        "previous_answers = []\n",
        "\n",
        "# Load external data from CSV\n",
        "def load_data(file):\n",
        "    print(\"Uploaded file path:\", file)  # Debugging to check file path\n",
        "    if not file or not os.path.isfile(file):  # Validate file path\n",
        "        return \"Error: No file uploaded or invalid file format. Please upload a valid CSV file.\"\n",
        "    try:\n",
        "        df = pd.read_csv(file)  # Attempt to load CSV\n",
        "        if \"title\" not in df.columns or \"content\" not in df.columns:\n",
        "            return \"Error: CSV file must have 'title' and 'content' columns.\"\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        return f\"Error loading file: {e}\"\n",
        "\n",
        "# Retriever: Retrieve relevant rows based on input query\n",
        "def retrieve_data(df, query, top_n=3):\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf_matrix = vectorizer.fit_transform(df['content'])\n",
        "        query_vector = vectorizer.transform([query])\n",
        "        similarity = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "        df['similarity'] = similarity\n",
        "        top_results = df.sort_values(by='similarity', ascending=False).head(top_n)\n",
        "        return top_results[['title', 'content', 'similarity']]\n",
        "    except Exception as e:\n",
        "        return f\"Error in retrieval process: {e}\"\n",
        "\n",
        "# Ranker: Rank retrieved results (already sorted by similarity)\n",
        "def rank_results(results):\n",
        "    return results.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "\n",
        "# Generator: Generate response using a text generation model\n",
        "def generate_response(query, context):\n",
        "    try:\n",
        "        generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "        # Truncate context to avoid input length issues\n",
        "        max_context_tokens = 100  # Adjust as needed\n",
        "        truncated_context = \" \".join(context.split()[:max_context_tokens])\n",
        "\n",
        "        # Adjust generation prompt\n",
        "        prompt = f\"Context: {truncated_context}\\nQuestion: {query}\\nAnswer:\"\n",
        "\n",
        "        # Use max_new_tokens to control output generation length\n",
        "        response = generator(prompt, max_new_tokens=50, num_return_sequences=1)\n",
        "        return response[0]['generated_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "# RAG Pipeline\n",
        "def rag_pipeline(file, query):\n",
        "    global previous_answers\n",
        "\n",
        "    # Handle common prompts\n",
        "    common_response = handle_common_prompts(query)\n",
        "    if common_response:\n",
        "        previous_answers.append(f\"User: {query}\\nAI: {common_response}\")\n",
        "        return \"\\n\".join(previous_answers)\n",
        "\n",
        "    # Load the data\n",
        "    df = load_data(file)\n",
        "    if isinstance(df, str):  # Error handling\n",
        "        return df\n",
        "\n",
        "    # Retrieve data\n",
        "    retrieved = retrieve_data(df, query)\n",
        "    if isinstance(retrieved, str):  # Error handling\n",
        "        return retrieved\n",
        "\n",
        "    # Rank results\n",
        "    ranked = rank_results(retrieved)\n",
        "\n",
        "    # Prepare context and generate response\n",
        "    context = \" \".join(ranked['content'].tolist())\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    # Store the answer\n",
        "    result = f\"Query: {query}\\nTop Results:\\n{ranked}\\n\\nGenerated Response:\\n{response}\"\n",
        "    previous_answers.append(result)\n",
        "\n",
        "    # Return previous answers\n",
        "    return \"\\n\".join(previous_answers)\n",
        "\n",
        "# Gradio UI\n",
        "interface = gr.Interface(\n",
        "    fn=rag_pipeline,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload CSV File (with 'title' and 'content')\"),\n",
        "        gr.Textbox(label=\"Enter your query\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Retrieval-Augmented Generation Demo\",\n",
        "    description=\"Upload a CSV file, enter a query, and see the RAG pipeline in action! For common prompts like 'Hi', you'll receive a friendly response.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WukVGDvnNmpf"
      },
      "source": [
        "# More refied code with error handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "fjzgm8GrMtnW",
        "outputId": "f0457a98-0ff4-4162-efc6-ffee1ce5cb01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://75fed1fd6b4c5a8131.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://75fed1fd6b4c5a8131.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# Global variable to store previous answers\n",
        "previous_answers = []\n",
        "\n",
        "# Load external data from CSV\n",
        "def load_data(file):\n",
        "    if file is None:  # Check if file is None\n",
        "        return \"Error: No file uploaded. Please upload a valid CSV file.\"\n",
        "    try:\n",
        "        # Use pandas to read the file directly\n",
        "        df = pd.read_csv(file)\n",
        "        if \"title\" not in df.columns or \"content\" not in df.columns:\n",
        "            return \"Error: CSV file must have 'title' and 'content' columns.\"\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        return f\"Error loading file: {e}\"\n",
        "\n",
        "# Retriever: Retrieve relevant rows based on input query\n",
        "def retrieve_data(df, query, top_n=3):\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf_matrix = vectorizer.fit_transform(df['content'])\n",
        "        query_vector = vectorizer.transform([query])\n",
        "        similarity = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "        df['similarity'] = similarity\n",
        "        top_results = df.sort_values(by='similarity', ascending=False).head(top_n)\n",
        "        return top_results[['title', 'content', 'similarity']]\n",
        "    except Exception as e:\n",
        "        return f\"Error in retrieval process: {e}\"\n",
        "\n",
        "# Ranker: Rank retrieved results (already sorted by similarity)\n",
        "def rank_results(results):\n",
        "    try:\n",
        "        return results.sort_values(by='similarity', ascending=False)\n",
        "    except Exception as e:\n",
        "        return f\"Error in ranking results: {e}\"\n",
        "\n",
        "# Generator: Generate response using a text generation model\n",
        "def generate_response(query, context):\n",
        "    try:\n",
        "        generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "        max_context_tokens = 100  # Truncate context to avoid input length issues\n",
        "        truncated_context = \" \".join(context.split()[:max_context_tokens])\n",
        "        prompt = f\"Context: {truncated_context}\\nQuestion: {query}\\nAnswer:\"\n",
        "        response = generator(prompt, max_new_tokens=50, num_return_sequences=1)\n",
        "        return response[0]['generated_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "# RAG Pipeline\n",
        "def rag_pipeline(file, query):\n",
        "    global previous_answers\n",
        "\n",
        "    # Load the data\n",
        "    df = load_data(file)\n",
        "    if isinstance(df, str):  # Error handling for data loading\n",
        "        return df\n",
        "\n",
        "    # Retrieve data\n",
        "    retrieved = retrieve_data(df, query)\n",
        "    if isinstance(retrieved, str):  # Error handling for retrieval\n",
        "        return retrieved\n",
        "\n",
        "    # Rank results\n",
        "    ranked = rank_results(retrieved)\n",
        "    if isinstance(ranked, str):  # Error handling for ranking\n",
        "        return ranked\n",
        "\n",
        "    # Prepare context and generate response\n",
        "    context = \" \".join(ranked['content'].tolist())\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    # Store the answer\n",
        "    result = f\"Query: {query}\\nTop Results:\\n{ranked}\\n\\nGenerated Response:\\n{response}\"\n",
        "    previous_answers.append(result)\n",
        "\n",
        "    return \"\\n\".join(previous_answers)\n",
        "\n",
        "# Gradio UI\n",
        "interface = gr.Interface(\n",
        "    fn=rag_pipeline,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload CSV File (with 'title' and 'content')\"),\n",
        "        gr.Textbox(label=\"Enter your query\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Retrieval-Augmented Generation Demo\",\n",
        "    description=\"Upload a CSV file, enter a query, and see the RAG pipeline in action!\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9_OAzgn6M5"
      },
      "source": [
        "This script implements a **Retrieval-Augmented Generation (RAG) pipeline** with an interactive user interface using **Gradio**. The code combines **retrieval** and **generation** techniques to answer user queries based on content uploaded in a CSV file. It also handles common prompts like Hi or Hello with predefined responses.\n",
        "\n",
        "---\n",
        "\n",
        "## **Detailed Breakdown**\n",
        "\n",
        "### **Imports**\n",
        "1. **`pandas as pd`**  \n",
        "   - Handles CSV file operations for loading and manipulating data.\n",
        "\n",
        "2. **`TfidfVectorizer`** and **`cosine_similarity`** (from `sklearn`):  \n",
        "   - `TfidfVectorizer`: Converts textual data into TF-IDF vectors (numerical representation of text).  \n",
        "   - `cosine_similarity`: Computes the similarity between two sets of text vectors.\n",
        "\n",
        "3. **`pipeline`** (from HuggingFace Transformers):  \n",
        "   - Provides pre-built pipelines for natural language tasks (e.g., `text-generation` using GPT-2).\n",
        "\n",
        "4. **`gradio as gr`**:  \n",
        "   - Creates an interactive web interface for user input/output.\n",
        "\n",
        "5. **`os`**:  \n",
        "   - Used for validating if the uploaded file exists and checking its format.\n",
        "\n",
        "---\n",
        "\n",
        "### **Global Variables**\n",
        "```python\n",
        "previous_answers = []\n",
        "```\n",
        "- A list to store and display past queries and responses so that the user can see prior interactions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Functions**\n",
        "\n",
        "#### **1. `load_data(file)`**\n",
        "- **Purpose**: Load and validate the CSV file uploaded by the user.\n",
        "\n",
        "- **Steps**:\n",
        "  1. Print the uploaded file path for debugging.\n",
        "  2. Check if the file exists and is valid using `os.path.isfile(file)`.\n",
        "  3. Use `pandas.read_csv()` to load the file.\n",
        "  4. Ensure the file contains `title` and `content` columns.\n",
        "  5. Return the dataframe if successful, or an error message otherwise.\n",
        "\n",
        "- **Why**: Ensures the pipeline starts with a valid CSV input.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. `retrieve_data(df, query, top_n=3)`**\n",
        "- **Purpose**: Retrieve the top N rows from the CSV file that are most similar to the query.\n",
        "\n",
        "- **Steps**:\n",
        "  1. Convert the `content` column into TF-IDF vectors using `TfidfVectorizer`.\n",
        "  2. Transform the input `query` into a TF-IDF vector.\n",
        "  3. Compute cosine similarity between the query vector and the content vectors.\n",
        "  4. Sort the rows by similarity score in descending order.\n",
        "  5. Return the top N rows (`title`, `content`, and `similarity`).\n",
        "\n",
        "- **Why**: Finds the most relevant information based on the query.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. `rank_results(results)`**\n",
        "- **Purpose**: Rank the retrieved results based on their similarity score.\n",
        "\n",
        "- **Steps**:\n",
        "  - Sort the results dataframe in descending order of similarity scores.\n",
        "\n",
        "- **Why**: Ensures the retrieved content is presented in the most relevant order.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. `generate_response(query, context)`**\n",
        "- **Purpose**: Generate a response using GPT-2 based on the input query and retrieved content.\n",
        "\n",
        "- **Steps**:\n",
        "  1. Use `pipeline(\"text-generation\", model=\"gpt2\")` to load GPT-2.\n",
        "  2. Truncate the context to **100 tokens** to avoid exceeding input length limits.\n",
        "  3. Construct a prompt combining the query and the retrieved context.\n",
        "  4. Generate text using the GPT-2 model with `max_new_tokens=50` to limit the response length.\n",
        "  5. Return the generated response.\n",
        "\n",
        "- **Why**: GPT-2 generates coherent answers based on the retrieved context.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. `rag_pipeline(file, query)`**\n",
        "- **Purpose**: End-to-end execution of the RAG pipeline.\n",
        "\n",
        "- **Steps**:\n",
        "  1. Check for common prompts (e.g., Hi) and return a predefined response.\n",
        "  2. Load the CSV file using `load_data`.\n",
        "  3. Retrieve the top relevant rows using `retrieve_data`.\n",
        "  4. Rank the results using `rank_results`.\n",
        "  5. Concatenate the retrieved content into a context string.\n",
        "  6. Generate a response using `generate_response`.\n",
        "  7. Append the query and response to the `previous_answers` list.\n",
        "  8. Return all previous answers for display.\n",
        "\n",
        "- **Why**: Integrates all components to handle queries, provide answers, and maintain conversation history.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Gradio Interface**\n",
        "```python\n",
        "interface = gr.Interface(\n",
        "    fn=rag_pipeline,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload CSV File (with 'title' and 'content')\"),\n",
        "        gr.Textbox(label=\"Enter your query\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Retrieval-Augmented Generation Demo\",\n",
        "    description=\"Upload a CSV file, enter a query, and see the RAG pipeline in action! For common prompts like 'Hi', you'll receive a friendly response.\"\n",
        ")\n",
        "```\n",
        "\n",
        "- **`fn=rag_pipeline`**: Connects the interface to the RAG pipeline function.\n",
        "- **`inputs`**:\n",
        "  - `gr.File`: Allows users to upload a CSV file.\n",
        "  - `gr.Textbox`: Allows users to input queries.\n",
        "- **`outputs=\"text\"`**: Displays the pipeline's response.\n",
        "- **`title` and `description`**: Provide context for the Gradio app.\n",
        "\n",
        "---\n",
        "\n",
        "### **Launch the Interface**\n",
        "```python\n",
        "interface.launch(share=True)\n",
        "```\n",
        "- Launches the Gradio app and provides a **shareable link** for remote access.\n",
        "\n",
        "---\n",
        "\n",
        "## **How It Works (Flow Summary)**\n",
        "\n",
        "1. **Upload a CSV File**:\n",
        "   - The file must contain `title` and `content` columns.\n",
        "\n",
        "2. **User Inputs a Query**:\n",
        "   - If the query is common (e.g., \"Hi\"), the pipeline returns a predefined response.\n",
        "   - Otherwise, the pipeline proceeds to retrieve and generate answers.\n",
        "\n",
        "3. **RAG Pipeline Execution**:\n",
        "   - Load and validate the CSV file.\n",
        "   - Retrieve the top relevant rows using **TF-IDF** and **cosine similarity**.\n",
        "   - Rank the results and concatenate their content into a context string.\n",
        "   - Generate a response using GPT-2 based on the query and retrieved context.\n",
        "\n",
        "4. **Display Response**:\n",
        "   - Returns the generated response along with the conversation history.\n",
        "\n",
        "---\n",
        "\n",
        "## **Example Scenarios**\n",
        "\n",
        "### **Case 1: Common Prompt**\n",
        "**Input**: \"Hi\"  \n",
        "**Output**:\n",
        "```\n",
        "User: Hi\n",
        "AI: Hello! How can I assist you today?\n",
        "```\n",
        "\n",
        "### **Case 2: Query after Uploading CSV**\n",
        "**Query**: \"What is Generative AI?\"  \n",
        "**Top Results**:\n",
        "| Title               | Content                                        | Similarity |\n",
        "|---------------------|------------------------------------------------|------------|\n",
        "| Generative AI Intro | Generative AI generates new data using models. | 0.92       |\n",
        "\n",
        "**Generated Response**:\n",
        "\"Generative AI refers to AI systems that create new content based on input patterns.\"\n",
        "\n",
        "---\n",
        "\n",
        "## **Key Benefits of the Code**\n",
        "\n",
        "1. **RAG Architecture**:\n",
        "   - Combines information retrieval and text generation to answer queries accurately.\n",
        "\n",
        "2. **Common Prompt Handling**:\n",
        "   - Responds to casual inputs like Hi with predefined friendly responses.\n",
        "\n",
        "3. **Interaction History**:\n",
        "   - Maintains previous answers for a conversational experience.\n",
        "\n",
        "4. **User-Friendly Interface**:\n",
        "   - Easy interaction using Gradio.\n",
        "\n",
        "---\n",
        "\n",
        "This implementation is modular, user-friendly, and demonstrates the combination of **retrieval-based** and **generative AI** techniques in a seamless pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSU8QSytTfWj"
      },
      "source": [
        "# SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOPvmb8JTz-D",
        "outputId": "1f599886-ca91-4511-9561-1943e60e148f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (7.5 kB)\n",
            "Downloading mysql_connector_python-9.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (33.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install mysql-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQThTMbfUf7i",
        "outputId": "25720347-98c2-4aa1-84b4-254f9840457f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vcz0OMixDHN",
        "outputId": "3ff8efbd-6f93-42a9-9672-2136768c6f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94 rows inserted successfully into product_data table.\n",
            "Database connection closed.\n"
          ]
        }
      ],
      "source": [
        "import mysql.connector\n",
        "\n",
        "# Database connection details\n",
        "db_config = {\n",
        "    \"host\": \"sql3.freesqldatabase.com\",\n",
        "    \"user\": \"sql3796581\",\n",
        "    \"password\": \"bSMmGthI1Z\",\n",
        "    \"database\": \"sql3796581\",\n",
        "    \"port\": 3306\n",
        "}\n",
        "\n",
        "# Complete data to be inserted\n",
        "data = [\n",
        "    (\"Apple iPhone 15 Pro Max\", \"Unit\", 1699),\n",
        "    (\"Samsung 85\\\" QLED TV\", \"Unit\", 3499),\n",
        "    (\"Dell XPS 17 Laptop\", \"Unit\", 2599),\n",
        "    (\"Apple MacBook Pro 16\\\"\", \"Unit\", 3199),\n",
        "    (\"Sony PlayStation 5\", \"Unit\", 499),\n",
        "    (\"Xbox Series X\", \"Unit\", 499),\n",
        "    (\"KitchenAid Professional Mixer\", \"Unit\", 799),\n",
        "    (\"Dyson V15 Vacuum\", \"Unit\", 899),\n",
        "    (\"Bose 700 Noise Cancelling Headphones\", \"Unit\", 379),\n",
        "    (\"Apple iPad Pro 12.9\\\"\", \"Unit\", 1299),\n",
        "    (\"Canon EOS R5 Camera\", \"Unit\", 3899),\n",
        "    (\"LG 75\\\" OLED TV\", \"Unit\", 3499),\n",
        "    (\"Microsoft Surface Laptop 5\", \"Unit\", 1899),\n",
        "    (\"NVIDIA GeForce RTX 4090 Graphics Card\", \"Unit\", 1599),\n",
        "    (\"Rolex Submariner Watch\", \"Piece\", 13499),\n",
        "    (\"Gucci Leather Handbag\", \"Piece\", 2899),\n",
        "    (\"Apple Watch Ultra\", \"Unit\", 799),\n",
        "    (\"Beats Studio Pro Headphones\", \"Unit\", 399),\n",
        "    (\"Yamaha Grand Piano\", \"Unit\", 13999),\n",
        "    (\"Peloton Bike+\", \"Unit\", 2495),\n",
        "    (\"Tesla Model 3 (Scale Model)\", \"Model\", 299),\n",
        "    (\"DJI Mavic 3 Drone\", \"Unit\", 2199),\n",
        "    (\"Samsung Galaxy Tab S9 Ultra\", \"Unit\", 1199),\n",
        "    (\"Apple AirPods Max\", \"Unit\", 549),\n",
        "    (\"HyperX Gaming Headset\", \"Unit\", 149),\n",
        "    (\"Logitech MX Master 3S Mouse\", \"Unit\", 109),\n",
        "    (\"Herman Miller Aeron Chair\", \"Unit\", 1599),\n",
        "    (\"HP Spectre x360 Laptop\", \"Unit\", 2199),\n",
        "    (\"Asus ROG Zephyrus Gaming Laptop\", \"Unit\", 2799),\n",
        "    (\"Sony A7 IV Camera\", \"Unit\", 2599),\n",
        "    (\"Breville Barista Espresso Machine\", \"Unit\", 1499),\n",
        "    (\"Whirlpool French Door Refrigerator\", \"Unit\", 2999),\n",
        "    (\"Samsung Galaxy Z Fold5\", \"Unit\", 129),\n",
        "    (\"Apple TV 4K\", \"Unit\", 399),\n",
        "    (\"GoPro HERO12 Black\", \"Unit\", 179),\n",
        "    (\"Microsoft Xbox Elite Wireless Controller\", \"Unit\", 479),\n",
        "    (\"Seiko Prospex Diver Watch\", \"Unit\", 699),\n",
        "    (\"North Face Expedition Jacket\", \"Unit\", 299),\n",
        "    (\"Patagonia Duffel Bag\", \"Unit\", 199),\n",
        "    (\"Columbia Titanium Hiking Boots\", \"Unit\", 99),\n",
        "    (\"Therm-a-Rest Sleeping Pad\", \"Unit\", 299),\n",
        "    (\"Garmin Forerunner 965\", \"Unit\", 249),\n",
        "    (\"Fitbit Sense 2\", \"Unit\", 199),\n",
        "    (\"Ray-Ban Aviator Sunglasses\", \"Unit\", 149),\n",
        "    (\"Oakley Holbrook XL Sunglasses\", \"Unit\", 699),\n",
        "    (\"Samsung Soundbar with Subwoofer\", \"Unit\", 499),\n",
        "    (\"JBL PartyBox 310 Speaker\", \"Unit\", 39),\n",
        "    (\"Tile Pro Tracker\", \"Unit\", 259),\n",
        "    (\"Echo Show 15 Smart Display\", \"Unit\", 249),\n",
        "    (\"Kindle Oasis eReader\", \"Unit\", 129),\n",
        "    (\"Instant Pot Ultra\", \"Unit\", 599),\n",
        "    (\"Shark IQ Robot Vacuum\", \"Unit\", 999),\n",
        "    (\"Lego Millennium Falcon Set\", \"Unit\", 299),\n",
        "    (\"Nespresso Lattissima Touch\", \"Unit\", 179),\n",
        "    (\"Anova Precision Cooker Pro\", \"Unit\", 329),\n",
        "    (\"Cricut Maker 3\", \"Unit\", 499),\n",
        "    (\"Epson EcoTank Printer\", \"Unit\", 179),\n",
        "    (\"Canon PIXMA Pro-200 Printer\", \"Unit\", 349),\n",
        "    (\"Sony WH-1000XM5 Headphones\", \"Unit\", 129),\n",
        "    (\"Apple Magic Keyboard\", \"Unit\", 149),\n",
        "    (\"Apple Magic Mouse\", \"Unit\", 399),\n",
        "    (\"Samsung Galaxy Watch6\", \"Unit\", 279),\n",
        "    (\"Withings ScanWatch\", \"Unit\", 159),\n",
        "    (\"Ninja Foodi XL Air Fryer\", \"Unit\", 599),\n",
        "    (\"Cosori Smart Air Fryer\", \"Unit\", 3999),\n",
        "    (\"iRobot Roomba Combo j7+\", \"Unit\", 5499),\n",
        "    (\"LG Washer and Dryer Set\", \"Unit\", 899),\n",
        "    (\"Samsung Bespoke Refrigerator\", \"Unit\", 129),\n",
        "    (\"Vitamix 750 Blender\", \"Unit\", 999),\n",
        "    (\"NutriBullet Blender Combo\", \"Unit\", 1499),\n",
        "    (\"DeWalt Cordless Drill Kit\", \"Unit\", 499),\n",
        "    (\"Black+Decker Tool Kit\", \"Unit\", 999),\n",
        "    (\"Ryobi Cordless Mower\", \"Unit\", 599),\n",
        "    (\"John Deere Lawn Tractor\", \"Unit\", 1399),\n",
        "    (\"Toro Power Max Snow Blower\", \"Unit\", 899),\n",
        "    (\"Husqvarna Chainsaw\", \"Unit\", 1599),\n",
        "    (\"Weber Genesis II Grill\", \"Unit\", 299),\n",
        "    (\"Traeger Timberline XL Pellet Grill\", \"Unit\", 349),\n",
        "    (\"Cuisinart Outdoor Pizza Oven\", \"Unit\", 499),\n",
        "    (\"Ooni Koda Gas Pizza Oven\", \"Unit\", 199),\n",
        "    (\"Yeti Tundra Cooler\", \"Unit\", 699),\n",
        "    (\"RTIC Hard Cooler\", \"Unit\", 249),\n",
        "    (\"Stanley Classic Vacuum Bottle\", \"Unit\", 1599),\n",
        "    (\"Hydro Flask Water Bottle\", \"Unit\", 1299),\n",
        "    (\"Altra Lone Peak Trail Running Shoes\", \"Unit\", 599),\n",
        "    (\"Hoka Bondi 8 Running Shoes\", \"Unit\", 499),\n",
        "    (\"Brooks Ghost 15 Running Shoes\", \"Unit\", 799),\n",
        "    (\"Sorel Caribou Winter Boots\", \"Unit\", 799),\n",
        "    (\"Timberland PRO Work Boots\", \"Unit\", 1999),\n",
        "    (\"New Balance Fresh Foam Shoes\", \"Unit\", 999),\n",
        "    (\"On Cloud Running Shoes\", \"Unit\", 199),\n",
        "    (\"Apple HomePod Mini\", \"Unit\", 179),\n",
        "    (\"Google Nest Hub Max\", \"Unit\", 349),\n",
        "    (\"Arlo Pro 4 Security Camera\", \"Unit\", 299),\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Connect to the database\n",
        "    connection = mysql.connector.connect(**db_config)\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Create table\n",
        "    create_table_query = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS product_data (\n",
        "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "        product_name VARCHAR(255),\n",
        "        uom VARCHAR(50),\n",
        "        price_usd DECIMAL(10, 2)\n",
        "    );\n",
        "    \"\"\"\n",
        "    cursor.execute(create_table_query)\n",
        "\n",
        "    # Insert data\n",
        "    insert_query = \"INSERT INTO product_data (product_name, uom, price_usd) VALUES (%s, %s, %s)\"\n",
        "    cursor.executemany(insert_query, data)\n",
        "\n",
        "    # Commit the transaction\n",
        "    connection.commit()\n",
        "\n",
        "    print(f\"{cursor.rowcount} rows inserted successfully into product_data table.\")\n",
        "\n",
        "except mysql.connector.Error as err:\n",
        "    print(f\"Error: {err}\")\n",
        "finally:\n",
        "    # Close the database connection\n",
        "    if connection.is_connected():\n",
        "        cursor.close()\n",
        "        connection.close()\n",
        "        print(\"Database connection closed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdxeV-WbyxgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oPVQ29D9y--_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuJ8_nd0iknH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# import pandas as pd\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# from transformers import pipeline\n",
        "# import mysql.connector\n",
        "# import gradio as gr\n",
        "\n",
        "# # Global variable to store previous answers\n",
        "# previous_answers = []\n",
        "\n",
        "# # Connect to MySQL and fetch data\n",
        "# def fetch_data_from_sql(host, user, password, database, table):\n",
        "#     try:\n",
        "#         # Establish the SQL connection\n",
        "#         connection = mysql.connector.connect(\n",
        "#             host=host,\n",
        "#             user=user,\n",
        "#             password=password,\n",
        "#             database=database\n",
        "#         )\n",
        "#         # Adjust the query to match your table structure\n",
        "#         query = f\"SELECT product_name AS title, CAST(price_usd AS CHAR) AS content FROM {table};\"\n",
        "#         df = pd.read_sql(query, connection)  # Load data into a DataFrame\n",
        "#         connection.close()\n",
        "#         if \"title\" not in df.columns or \"content\" not in df.columns:\n",
        "#             return \"Error: Table must have 'product_name' and 'price_usd' columns.\"\n",
        "#         return df\n",
        "#     except Exception as e:\n",
        "#         return f\"Error connecting to database: {e}\"\n",
        "\n",
        "# # Retriever: Retrieve relevant rows based on input query\n",
        "# def retrieve_data(df, query, top_n=3):\n",
        "#     try:\n",
        "#         vectorizer = TfidfVectorizer(stop_words='english')\n",
        "#         tfidf_matrix = vectorizer.fit_transform(df['content'])\n",
        "#         query_vector = vectorizer.transform([query])\n",
        "#         similarity = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "#         df['similarity'] = similarity\n",
        "#         top_results = df.sort_values(by='similarity', ascending=False).head(top_n)\n",
        "#         return top_results[['title', 'content', 'similarity']]\n",
        "#     except Exception as e:\n",
        "#         return f\"Error in retrieval process: {e}\"\n",
        "\n",
        "# # Ranker: Rank retrieved results (already sorted by similarity)\n",
        "# def rank_results(results):\n",
        "#     return results.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "# # Generator: Generate response using a text generation model\n",
        "# def generate_response(query, context):\n",
        "#     try:\n",
        "#         generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "#         # Truncate context to avoid input length issues\n",
        "#         max_context_tokens = 100  # Adjust as needed\n",
        "#         truncated_context = \" \".join(context.split()[:max_context_tokens])\n",
        "\n",
        "#         # Adjust generation prompt\n",
        "#         prompt = f\"Context: {truncated_context}\\nQuestion: {query}\\nAnswer:\"\n",
        "\n",
        "#         # Use max_new_tokens to control output generation length\n",
        "#         response = generator(prompt, max_new_tokens=50, num_return_sequences=1)\n",
        "#         return response[0]['generated_text']\n",
        "#     except Exception as e:\n",
        "#         return f\"Error generating response: {e}\"\n",
        "\n",
        "# # RAG Pipeline\n",
        "# def rag_pipeline(host, user, password, database, table, query):\n",
        "#     global previous_answers\n",
        "\n",
        "#     # Fetch data from SQL\n",
        "#     df = fetch_data_from_sql(host, user, password, database, table)\n",
        "#     if isinstance(df, str):  # Error handling\n",
        "#         return df\n",
        "\n",
        "#     # Retrieve data\n",
        "#     retrieved = retrieve_data(df, query)\n",
        "#     if isinstance(retrieved, str):  # Error handling\n",
        "#         return retrieved\n",
        "\n",
        "#     # Rank results\n",
        "#     ranked = rank_results(retrieved)\n",
        "\n",
        "#     # Prepare context and generate response\n",
        "#     context = \" \".join(ranked['content'].tolist())\n",
        "#     response = generate_response(query, context)\n",
        "\n",
        "#     # Store the answer\n",
        "#     result = f\"Query: {query}\\nTop Results:\\n{ranked}\\n\\nGenerated Response:\\n{response}\"\n",
        "#     previous_answers.append(result)\n",
        "\n",
        "#     # Return previous answers\n",
        "#     return \"\\n\".join(previous_answers)\n",
        "\n",
        "# # Gradio UI\n",
        "# interface = gr.Interface(\n",
        "#     fn=rag_pipeline,\n",
        "#     inputs=[\n",
        "#         gr.Textbox(label=\"Enter SQL Host (e.g., localhost)\"),\n",
        "#         gr.Textbox(label=\"Enter SQL User\"),\n",
        "#         gr.Textbox(label=\"Enter SQL Password\", type=\"password\"),\n",
        "#         gr.Textbox(label=\"Enter SQL Database Name\"),\n",
        "#         gr.Textbox(label=\"Enter SQL Table Name\"),\n",
        "#         gr.Textbox(label=\"Enter your query\"),\n",
        "#     ],\n",
        "#     outputs=\"text\",\n",
        "#     title=\"Retrieval-Augmented Generation (RAG) with SQL\",\n",
        "#     description=\"Connect to a MySQL database, fetch data, and perform RAG to generate responses. Enter database credentials, table details, and your query.\"\n",
        "# )\n",
        "\n",
        "# # Launch the interface\n",
        "# interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code which fecthes but the respone is  Hallucinating"
      ],
      "metadata": {
        "id": "pjjPPWZHZy2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DZtBKIWFTg-q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "43081336-b58d-40f1-9fb6-70e20205ee56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b5269ff9a735be9c9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b5269ff9a735be9c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline\n",
        "import mysql.connector\n",
        "import gradio as gr\n",
        "\n",
        "# Global variable to store previous answers\n",
        "previous_answers = []\n",
        "\n",
        "# Fetch data from SQL database\n",
        "def fetch_data_from_sql(host, user, password, database, table):\n",
        "    try:\n",
        "        connection = mysql.connector.connect(\n",
        "            host=host,\n",
        "            user=user,\n",
        "            password=password,\n",
        "            database=database\n",
        "        )\n",
        "        query = f\"SELECT product_name AS title, CAST(price_usd AS CHAR) AS content FROM {table};\"\n",
        "        df = pd.read_sql(query, connection)\n",
        "        connection.close()\n",
        "\n",
        "        if \"title\" not in df.columns or \"content\" not in df.columns:\n",
        "            return \"Error: Table must have 'product_name' and 'price_usd' columns.\"\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        return f\"Error connecting to database: {e}\"\n",
        "\n",
        "# Retrieve top relevant products based on query\n",
        "def retrieve_data(df, query, top_n=3):\n",
        "    try:\n",
        "        # Combine title and content to improve match\n",
        "        df['combined'] = df['title'].astype(str) + \" \" + df['content'].astype(str)\n",
        "\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf_matrix = vectorizer.fit_transform(df['combined'])\n",
        "        query_vector = vectorizer.transform([query])\n",
        "        similarity = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "\n",
        "        df['similarity'] = similarity\n",
        "        top_results = df.sort_values(by='similarity', ascending=False).head(top_n)\n",
        "        return top_results[['title', 'content', 'similarity']]\n",
        "    except Exception as e:\n",
        "        return f\"Error in retrieval process: {e}\"\n",
        "\n",
        "# Ranker is redundant now, but kept for future use\n",
        "def rank_results(results):\n",
        "    return results.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "# Generate response using Hugging Face model\n",
        "def generate_response(query, context):\n",
        "    try:\n",
        "        generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "        max_context_tokens = 100\n",
        "        truncated_context = \" \".join(context.split()[:max_context_tokens])\n",
        "\n",
        "        prompt = f\"Context: {truncated_context}\\nQuestion: {query}\\nAnswer:\"\n",
        "        response = generator(prompt, max_new_tokens=50, num_return_sequences=1)\n",
        "        return response[0]['generated_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "# RAG Orchestration\n",
        "def rag_pipeline(host, user, password, database, table, query):\n",
        "    global previous_answers\n",
        "\n",
        "    df = fetch_data_from_sql(host, user, password, database, table)\n",
        "    if isinstance(df, str):\n",
        "        return df\n",
        "\n",
        "    retrieved = retrieve_data(df, query)\n",
        "    if isinstance(retrieved, str):\n",
        "        return retrieved\n",
        "\n",
        "    ranked = rank_results(retrieved)\n",
        "    context = \" \".join(ranked['content'].tolist())\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    result = f\"Query: {query}\\nTop Results:\\n{ranked}\\n\\nGenerated Response:\\n{response}\"\n",
        "    previous_answers.append(result)\n",
        "    return \"\\n\".join(previous_answers)\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=rag_pipeline,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter SQL Host (e.g., localhost)\"),\n",
        "        gr.Textbox(label=\"Enter SQL User\"),\n",
        "        gr.Textbox(label=\"Enter SQL Password\", type=\"password\"),\n",
        "        gr.Textbox(label=\"Enter SQL Database Name\"),\n",
        "        gr.Textbox(label=\"Enter SQL Table Name\"),\n",
        "        gr.Textbox(label=\"Enter your query\"),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Retrieval-Augmented Generation (RAG) with SQL\",\n",
        "    description=\"Connect to a MySQL database, fetch data, and perform RAG to generate responses. Enter database credentials, table details, and your query.\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifed code to reduce hallucinating GPT-2 output"
      ],
      "metadata": {
        "id": "etQQtXpfaFJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline\n",
        "import mysql.connector\n",
        "import gradio as gr\n",
        "\n",
        "# Store previous responses\n",
        "previous_answers = []\n",
        "\n",
        "# Fetch data from SQL database\n",
        "def fetch_data_from_sql(host, user, password, database, table):\n",
        "    try:\n",
        "        connection = mysql.connector.connect(\n",
        "            host=host,\n",
        "            user=user,\n",
        "            password=password,\n",
        "            database=database\n",
        "        )\n",
        "        query = f\"SELECT product_name AS title, CAST(price_usd AS CHAR) AS content FROM {table};\"\n",
        "        df = pd.read_sql(query, connection)\n",
        "        connection.close()\n",
        "\n",
        "        if \"title\" not in df.columns or \"content\" not in df.columns:\n",
        "            return \"Error: Table must have 'product_name' and 'price_usd' columns.\"\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        return f\"Error connecting to database: {e}\"\n",
        "\n",
        "# Retrieve relevant entries using TF-IDF on title + content\n",
        "def retrieve_data(df, query, top_n=3):\n",
        "    try:\n",
        "        df['combined'] = df['title'].astype(str) + \" \" + df['content'].astype(str)\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf_matrix = vectorizer.fit_transform(df['combined'])\n",
        "        query_vector = vectorizer.transform([query])\n",
        "        similarity = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "        df['similarity'] = similarity\n",
        "        top_results = df.sort_values(by='similarity', ascending=False).head(top_n)\n",
        "        return top_results[['title', 'content', 'similarity']]\n",
        "    except Exception as e:\n",
        "        return f\"Error in retrieval process: {e}\"\n",
        "\n",
        "# Ranker: kept for clarity\n",
        "def rank_results(results):\n",
        "    return results.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "# Generator: use GPT-2 with instruction-based prompt\n",
        "def generate_response(query, context):\n",
        "    try:\n",
        "        generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "        max_context_tokens = 100\n",
        "        truncated_context = \" \".join(context.split()[:max_context_tokens])\n",
        "\n",
        "        prompt = f\"\"\"You are an assistant trained to answer questions strictly based on the provided context.\n",
        "Extract the exact price from the context for the product mentioned in the question.\n",
        "\n",
        "Context:\n",
        "{truncated_context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        response = generator(prompt, max_new_tokens=50, num_return_sequences=1)\n",
        "        return response[0]['generated_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "# RAG pipeline\n",
        "def rag_pipeline(host, user, password, database, table, query):\n",
        "    global previous_answers\n",
        "\n",
        "    df = fetch_data_from_sql(host, user, password, database, table)\n",
        "    if isinstance(df, str):\n",
        "        return df\n",
        "\n",
        "    retrieved = retrieve_data(df, query)\n",
        "    if isinstance(retrieved, str):\n",
        "        return retrieved\n",
        "\n",
        "    ranked = rank_results(retrieved)\n",
        "\n",
        "    # FIX: Build context from title + content to avoid KeyError\n",
        "    context = \" \".join((ranked['title'] + \" \" + ranked['content']).tolist())\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    result = f\"Query: {query}\\nTop Results:\\n{ranked}\\n\\nGenerated Response:\\n{response}\"\n",
        "    previous_answers.append(result)\n",
        "    return \"\\n\".join(previous_answers)\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=rag_pipeline,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter SQL Host (e.g., localhost)\"),\n",
        "        gr.Textbox(label=\"Enter SQL User\"),\n",
        "        gr.Textbox(label=\"Enter SQL Password\", type=\"password\"),\n",
        "        gr.Textbox(label=\"Enter SQL Database Name\"),\n",
        "        gr.Textbox(label=\"Enter SQL Table Name\"),\n",
        "        gr.Textbox(label=\"Enter your query\"),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Retrieval-Augmented Generation (RAG) with SQL\",\n",
        "    description=\"Connect to a MySQL database, fetch data, and perform RAG to generate responses. Enter database credentials, table details, and your query.\"\n",
        ")\n",
        "\n",
        "# Launch app\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "Yy-4zDR2a-ws",
        "outputId": "55c0cabe-f995-4233-9c0b-997ffe463f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bc2d16d3887c90cc46.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bc2d16d3887c90cc46.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}